{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oskar tracker for transcriptomes\n",
    "- Authors: Savandara BESSE & Leo BLONDEL\n",
    "- Creation: 10-05-2019\n",
    "- Modification: 10-27-2019\n",
    "______________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import os, progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.A : Create protein sequences from TSA nucleotide sequences\n",
    "    - Unzip files\n",
    "    - Rename files \n",
    "    - Translation (with clean translation end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_TSA_inputs(TSA_path, protein_path):\n",
    "    protein_list = []\n",
    "    bar = progressbar.ProgressBar()\n",
    "    if not os.path.isdir(protein_path):\n",
    "        os.mkdir(protein_path)\n",
    "        \n",
    "#     os.system('gunzip {}/*'.format(TSA_path))\n",
    "#     os.system('rename \\'s/fsa_nt$/fasta/\\' {}/*.fsa_nt'.format(TSA_path))\n",
    "    \n",
    "    for TSA in bar(os.listdir(TSA_path)):\n",
    "        INPUT = os.path.join(TSA_path, TSA)\n",
    "        OUTPUT = os.path.join(protein_path, 'translated_{}'.format(TSA))\n",
    "        os.system('transeq -sequence {} -frame 6 -trim -clean -outseq {}'.format(INPUT,OUTPUT))    \n",
    "        protein_list.append(OUTPUT)\n",
    "    return protein_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1114 of 1114) |####################| Elapsed Time: 0:49:34 Time:  0:49:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.08 s, sys: 3.6 s, total: 6.67 s\n",
      "Wall time: 57min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "TSA_path = '/media/savvy/DATA2/savvy/EXTAVOUR/SOURCES/TSA/TSA_INPUTS'\n",
    "protein_path = '/media/savvy/DATA2/savvy/EXTAVOUR/SOURCES/TSA/TSA_PROTEIN'\n",
    "translated_TSA = build_TSA_inputs(TSA_path, protein_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (168 of 168) |######################| Elapsed Time: 0:18:03 Time:  0:18:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 340 ms, sys: 830 ms, total: 1.17 s\n",
      "Wall time: 18min 3s\n"
     ]
    }
   ],
   "source": [
    "## Crustacean analysis 2017\n",
    "%%time \n",
    "TSA_path = '/media/lblondel/5D1FA0DA2BE76E76/savy/SOURCES/TSA_INPUTS'\n",
    "protein_path = '/media/lblondel/5D1FA0DA2BE76E76/savy/SOURCES/TSA_PROTEIN'\n",
    "translated_TSA = build_TSA_inputs(TSA_path, protein_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.B: Collect GCF protein\n",
    "    - Copy GCF protein fasta files\n",
    "    - Gunzip them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reach_Proteins(currentFolder):\n",
    "    for gFile in os.listdir(currentFolder):\n",
    "        if '_protein.faa.gz' in gFile :\n",
    "            return gFile\n",
    "        \n",
    "def build_GCF_inputs(genome_path, res_path):\n",
    "    for folder in os.listdir(genome_path): \n",
    "        if 'GCF' in folder :\n",
    "            currentFolder = os.path.join(genome_path, folder)\n",
    "            proteome = reach_Proteins(currentFolder)\n",
    "            target = os.path.join(genome_path, currentFolder, proteome)\n",
    "            os.system('cp {} {}'.format(target, res_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "genome_path = '/media/lblondel/5D1FA0DA2BE76E76/savy/SOURCES/Genomes'\n",
    "protein_path = '/media/lblondel/5D1FA0DA2BE76E76/savy/SOURCES/GCF_PROTEIN'\n",
    "build_GCF_inputs(genome_path, protein_path)\n",
    "os.system('gunzip {}/*'.format(protein_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.C: Collect GCA protein\n",
    "    - Prepare Augustus inputs\n",
    "    - Run Augustus annotations on cluster\n",
    "    - Collect GCA gff files \n",
    "    - Convert them into protein fasta files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reach_Genes(currentFolder):\n",
    "    all_genomic_files = [ gFile for gFile in os.listdir(currentFolder) if '_genomic.fna.gz' in gFile ]\n",
    "    if len(all_genomic_files) > 1 :\n",
    "        for gFile in all_genomic_files :\n",
    "            if ('cds' in gFile) or ('rna' in gFile):\n",
    "                pass\n",
    "            else :\n",
    "                return gFile\n",
    "    else :\n",
    "        return all_genomic_files[0]\n",
    "        \n",
    "def build_GCA_inputs(genome_path, res_path):\n",
    "    for folder in os.listdir(genome_path): \n",
    "        if 'GCA' in folder :\n",
    "            currentFolder = os.path.join(genome_path, folder)\n",
    "            proteome = reach_Genes(currentFolder)\n",
    "            target = os.path.join(genome_path, currentFolder, proteome)\n",
    "            os.system('cp {} {}'.format(target, res_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create inputs for Augustus\n",
    "%%time \n",
    "genome_path = '/media/lblondel/5D1FA0DA2BE76E76/savy/SOURCES/Genomes'\n",
    "res_path = '/media/lblondel/5D1FA0DA2BE76E76/savy/SOURCES/GCA_INPUTS'\n",
    "build_GCA_inputs(genome_path, res_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### /!\\ After collecting GFF annotation files from Cluster\n",
    "    - Run getAnnoFasta.pl\n",
    "    - Move proteins files in GCA_protein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Track Oskar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.6 ms, sys: 23.9 ms, total: 60.5 ms\n",
      "Wall time: 27min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "lotus_model = '../Data/Oskar_hmm/LOTUS_CONSENSUS.hmm'\n",
    "osk_model = '../Data/Oskar_hmm/OSK_CONSENSUS.hmm'\n",
    "protein_path = '/media/savvy/DATA2/savvy/EXTAVOUR/SOURCES/TSA/TSA_PROTEIN'\n",
    "result_path = '/media/savvy/DATA2/savvy/EXTAVOUR/SOURCES/TSA/TSA_RESULT'\n",
    "os.system('python3 execute_hmmsearch.py -a TSA -p {} -l {} -o {} -r {}'.format(protein_path, lotus_model, osk_model, result_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 ms, sys: 10.9 ms, total: 23 ms\n",
      "Wall time: 6min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "## Crustacean analysis \n",
    "lotus_model = '../Data/Oskar_hmm/LOTUS_CONSENSUS.hmm'\n",
    "osk_model = '../Data/Oskar_hmm/OSK_CONSENSUS.hmm'\n",
    "protein_path = '/media/lblondel/5D1FA0DA2BE76E76/savy/SOURCES/TSA_PROTEIN'\n",
    "result_path = '/media/lblondel/5D1FA0DA2BE76E76/savy/SOURCES/TSA_RESULT'\n",
    "os.system('python3 execute_hmmsearch.py -a TSA -p {} -l {} -o {} -r {}'.format(protein_path, lotus_model, osk_model, result_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.87 ms, sys: 3.64 ms, total: 6.51 ms\n",
      "Wall time: 32.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "lotus_model = '../Data/Oskar_hmm/LOTUS_CONSENSUS.hmm'\n",
    "osk_model = '../Data/Oskar_hmm/OSK_CONSENSUS.hmm'\n",
    "protein_path = '/media/lblondel/5D1FA0DA2BE76E76/savy/SOURCES/GCF_PROTEIN'\n",
    "result_path = '/media/lblondel/5D1FA0DA2BE76E76/savy/SOURCES/GCF_RESULT'\n",
    "os.system('python3 execute_hmmsearch.py -a GCF -p {} -l {} -o {} -r {}'.format(protein_path, lotus_model, osk_model, result_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.68 ms, sys: 0 ns, total: 6.68 ms\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "lotus_model = '../Data/Oskar_hmm/LOTUS_CONSENSUS.hmm'\n",
    "osk_model = '../Data/Oskar_hmm/OSK_CONSENSUS.hmm'\n",
    "protein_path = '/media/lblondel/5D1FA0DA2BE76E76/savy/SOURCES/GCA_PROTEIN'\n",
    "result_path = '/media/lblondel/5D1FA0DA2BE76E76/savy/SOURCES/GCA_RESULT'\n",
    "os.system('python3 execute_hmmsearch.py -a GCA -p {} -l {} -o {} -r {}'.format(protein_path, lotus_model, osk_model, result_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 : Collect Oskar candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SearchIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def collect_Table(TSA, HMM):\n",
    "    for DOM in HMM :\n",
    "        if TSA in DOM :\n",
    "            return DOM\n",
    "        \n",
    "def collect_Hits(result_path, hmmerTable):\n",
    "    f = open(os.path.join(result_path, hmmerTable))\n",
    "    tmp = [ line for line in f.readlines() if '#' not in line ]\n",
    "    f.close()\n",
    "    if len(tmp) != 0 : \n",
    "        return [ hit.id for hit in SearchIO.read(hmmerTable, 'hmmer3-tab') if hit.evalue <= 0.05 ]\n",
    "    return []\n",
    "    \n",
    "\n",
    "def oskar_analysis(ID):\n",
    "    lotus_res = os.path.join(result_path, collect_Table(ID, LOTUS))\n",
    "    osk_res = os.path.join(result_path, collect_Table(ID, OSK))\n",
    "\n",
    "    lotus_hits = collect_Hits(result_path, lotus_res)\n",
    "    osk_hits = collect_Hits(result_path, osk_res)\n",
    "    oskar_hits = list(set(lotus_hits) & set(osk_hits))\n",
    "    \n",
    "    if len(oskar_hits) == 0 :\n",
    "        oskar_hits = 'None'\n",
    "    else : \n",
    "        oskar_hits = ','.join(list(set(lotus_hits) & set(osk_hits)))\n",
    "    if len(lotus_hits) == 0 :\n",
    "        lotus_hits = 'None'\n",
    "    else :\n",
    "        lotus_hits = ','.join(list(lotus_hits))\n",
    "    if len(osk_hits) == 0:\n",
    "        osk_hits = 'None'\n",
    "    else : \n",
    "        osk_hits = ','.join(list(osk_hits))\n",
    "\n",
    "    return [ID, lotus_hits, osk_hits, oskar_hits ]\n",
    "        \n",
    "PGC_mode = {\n",
    "    'Diplura':'Induction',\n",
    "    'Archaeognatha':'Induction',\n",
    "    'Zygentoma':'Induction',\n",
    "    'Odonata':'Induction',\n",
    "    'Ephemeroptera':'Induction',\n",
    "    'Zoraptera':'Induction',\n",
    "    'Dermaptera':'Induction',\n",
    "    'Plecoptera':'Induction',\n",
    "    'Orthoptera':'Induction',\n",
    "    'Mantophasmatodea':'Induction',\n",
    "    'Grylloblattodea':'Induction',\n",
    "    'Embioptera':'Induction',\n",
    "    'Phasmatodea':'Induction',\n",
    "    'Mantodea':'Induction',\n",
    "    'Blattodea':'Induction',\n",
    "    'Isoptera':'Induction',\n",
    "    'Thysanoptera':'Induction',\n",
    "    'Hemiptera':'Induction',\n",
    "    'Phthiraptera':'Induction',\n",
    "    'Psocoptera':'Induction',\n",
    "    'Hymenoptera':'Inheritance',\n",
    "    'Raphidioptera':'Inheritance',\n",
    "    'Megaloptera':'Inheritance',\n",
    "    'Neuroptera':'Inheritance',\n",
    "    'Strepsiptera':'Inheritance',\n",
    "    'Coleoptera':'Inheritance',\n",
    "    'Trichoptera':'Inheritance',\n",
    "    'Lepidoptera':'Inheritance',\n",
    "    'Siphonaptera':'Inheritance',\n",
    "    'Mecoptera':'Inheritance',\n",
    "    'Diptera':'Inheritance'\n",
    "}\n",
    "\n",
    "def set_augustus_model(order, table):\n",
    "    if order == 'Diplura' :\n",
    "        hmm_order = 'frankliniella_occidentalis'\n",
    "    elif order == 'Archaeognatha':\n",
    "        hmm_order = 'frankliniella_occidentalis'\n",
    "    elif order == 'Odonata' :\n",
    "        hmm_order = 'zootermopsis_nevadensis'\n",
    "    elif order == 'Ephemeroptera' :\n",
    "        hmm_order = 'frankliniella_occidentalis'\n",
    "    elif order == 'Plecoptera' :\n",
    "        hmm_order = 'zootermopsis_nevadensis'\n",
    "    elif order == 'Orthoptera' :\n",
    "        hmm_order = 'zootermopsis_nevadensis'\n",
    "    elif order == 'Phasmatodea' :\n",
    "        hmm_order = 'zootermopsis_nevadensis'\n",
    "    elif order == 'Blattodea':\n",
    "        hmm_order = 'zootermopsis_nevadensis'\n",
    "    elif order == 'Thysanoptera' :\n",
    "        hmm_order = 'frankliniella_occidentalis'\n",
    "    elif order == 'Hemiptera' :\n",
    "        hmm_order = 'bemisia_tabaci'\n",
    "    elif order == 'Phthiraptera' :\n",
    "        hmm_order = 'pediculus_humanus'\n",
    "    elif order == 'Hymenoptera' :\n",
    "        hmm_order = 'apis_mellifera'\n",
    "    elif order == 'Strepsiptera' :\n",
    "        hmm_order = 'tribolium_castaneum'\n",
    "    elif order == 'Coleoptera' :\n",
    "        hmm_order = 'tribolium_castaneum'\n",
    "    elif order == 'Trichoptera' :\n",
    "        hmm_order = 'papilio_xuthus'\n",
    "    elif order == 'Lepidoptera' :\n",
    "        hmm_order = 'papilio_xuthus'\n",
    "    elif order == 'Siphonaptera' :\n",
    "        hmm_order = 'ctenophalides_felis'\n",
    "    elif order == 'Diptera' :\n",
    "        family = table[table['order_name'] == order ]['family_name']\n",
    "        if 'Culicidae' in family :\n",
    "            hmm_order = 'aedes'\n",
    "        elif 'Pteromalidae' in family :\n",
    "            hmm_order = 'nasonia'\n",
    "        else :\n",
    "            hmm_order = 'fly'\n",
    "    return hmm_order\n",
    "\n",
    "def set_germ_cell_formation(x):\n",
    "    return PGC_mode[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.5 s, sys: 28 ms, total: 1.53 s\n",
      "Wall time: 1.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tsa_path = '../Data/01_Oskar_identification/hmmsearch_raw_results/TSA'\n",
    "IDs = list(set([ TSA.split('_')[0] for TSA in os.listdir('../Data/01_Oskar_identification/hmmsearch_raw_results/TSA') ]))\n",
    "LOTUS = [ domain for domain in sorted(os.listdir(tsa_path)) if 'lotus' in domain ]\n",
    "OSK = [ domain for domain in sorted(os.listdir(tsa_path)) if 'osk' in domain ]\n",
    "TSA_OSKAR = list(map(oskar_analysis, IDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMP = pd.DataFrame(TSA_OSKAR, columns=['tsa_abrv', 'lotus_hits', 'osk_hits', 'oskar_hits'])\n",
    "TSA = pd.read_csv('../Data/01_Oskar_identification/2019/transcriptome_insect_database.csv')\n",
    "\n",
    "TSA['pgc_mode'] = TSA['order_name'].apply(set_germ_cell_formation)\n",
    "TSA['tsa_abrv'] = [ '{}{}'.format(TSA['tsa_id'][i][:5], TSA['tsa_id'][i].split('.')[1]) for i in range(len(TSA)) ]\n",
    "\n",
    "TSA = TSA.merge(TMP, on='tsa_abrv')\n",
    "TSA.to_csv('../Data/01_Oskar_identification/oskar_tracker_results/TSA/tsa_oskar_results.csv', index=False, na_rep='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 327 ms, sys: 37.6 ms, total: 364 ms\n",
      "Wall time: 433 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Curstacean analysis \n",
    "tsa_path = '../Data/01_Oskar_identification/hmmsearch_raw_results/TSA_crustacea'\n",
    "IDs = list(set([ TSA.split('_')[0] for TSA in os.listdir('../Data/01_Oskar_identification/hmmsearch_raw_results/TSA_crustacea') ]))\n",
    "LOTUS = [ domain for domain in sorted(os.listdir(tsa_path)) if 'lotus' in domain ]\n",
    "OSK = [ domain for domain in sorted(os.listdir(tsa_path)) if 'osk' in domain ]\n",
    "TSA_OSKAR = list(map(oskar_analysis, IDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatTSA(x):\n",
    "    x = x.replace('.1', '')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP = pd.DataFrame(TSA_OSKAR, columns=['TSA', 'lotus_hits', 'osk_hits', 'oskar_hits'])\n",
    "TMP['TSA'] = TMP['TSA'].apply(formatTSA)\n",
    "TSA = pd.read_csv('../Data/01_Oskar_identification/2017/transcriptome_crustacean_database.csv')\n",
    "# TSA['pgc_mode'] = TSA['order_name'].apply(set_germ_cell_formation)\n",
    "TSA = TSA.merge(TMP, on='TSA')\n",
    "TSA.to_csv('../Data/01_Oskar_identification/oskar_tracker_results/TSA_crustacea/tsa_oskar_results.csv', index=False, na_rep='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcf_path = '../Data/01_Oskar_identification/hmmsearch_raw_results/GCF'\n",
    "IDs = list(set([ '{}_{}'.format(GCF.split('_')[0], GCF.split('_')[1]) for GCF in os.listdir(gcf_path) ]))\n",
    "LOTUS = [ domain for domain in sorted(os.listdir(gcf_path)) if 'lotus' in domain ]\n",
    "OSK = [ domain for domain in sorted(os.listdir(gcf_path)) if 'osk' in domain ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCF_OSKAR = list(map(oskar_analysis, IDs))\n",
    "TMP = pd.DataFrame(GCF_OSKAR, columns=['genome_id', 'lotus_hits', 'osk_hits', 'oskar_hits'])\n",
    "\n",
    "GCF = pd.read_csv('../Data/01_Oskar_identification/2019/genome_insect_database.csv')\n",
    "GCF['pgc_mode'] = GCF['order_name'].apply(set_germ_cell_formation)\n",
    "\n",
    "GCF = GCF.merge(TMP, on='genome_id')\n",
    "GCF.to_csv('../Data/01_Oskar_identification/oskar_tracker_results/GCF/gcf_oskar_results.csv', index=False, na_rep='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gca_path = '../Data/01_Oskar_identification/hmmsearch_raw_results/GCA'\n",
    "IDs = list(set([ '{}_{}'.format(GCA.split('_')[0], GCA.split('_')[1]) for GCA in os.listdir(gca_path) ]))\n",
    "LOTUS = [ domain for domain in sorted(os.listdir(gca_path)) if 'lotus' in domain ]\n",
    "OSK = [ domain for domain in sorted(os.listdir(gca_path)) if 'osk' in domain ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCA_OSKAR = list(map(oskar_analysis, IDs))\n",
    "TMP = pd.DataFrame(GCA_OSKAR, columns=['genome_id', 'lotus_hits', 'osk_hits', 'oskar_hits'])\n",
    "\n",
    "GCA = pd.read_csv('../Data/01_Oskar_identification/2019/genome_insect_database.csv')\n",
    "GCA['pgc_mode'] = GCA['order_name'].apply(set_germ_cell_formation)\n",
    "GCA['augustus_model'] = GCA['order_name'].apply(set_augustus_model, args=(GCA,))\n",
    "GCA = GCA.merge(TMP, on='genome_id')\n",
    "GCA.to_csv('../Data/01_Oskar_identification/oskar_tracker_results/GCA/gca_oskar_results.csv', index=False, na_rep='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Collect candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_genome(x, table):\n",
    "    return table[table['oskar_hits'].str.contains(x)]['genome_id'].values[0]\n",
    "\n",
    "def retrieveSeq(seqID, dataType, fastaFile):\n",
    "    for seqRecord in SeqIO.parse(fastaFile, 'fasta'):\n",
    "        if seqID in seqRecord.id :\n",
    "            if 'TSA' in dataType :\n",
    "                seqRecord.seq = format_Seq(seqRecord.seq)\n",
    "            return seqRecord\n",
    "        \n",
    "def first_AA(seq):\n",
    "    for i in range(len(seq)):\n",
    "        if 'M' in seq[i]:\n",
    "            return i\n",
    "\n",
    "def format_Seq(seq):\n",
    "    return seq[first_AA(seq):]\n",
    "\n",
    "def save_oskar(TABLE, protein_path, dataType, result_file):\n",
    "    OSKAR_SEQ = [] \n",
    "    OSKAR_HITS = [ ID for LIST in TABLE[TABLE['oskar_hits'] != 'None']['oskar_hits'] for ID in LIST.split(',') ]\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for SEQ in bar(OSKAR_HITS): \n",
    "        if 'TSA' in dataType :\n",
    "            ID = SEQ[:4]\n",
    "        else :\n",
    "            ID = collect_genome(SEQ, TABLE)\n",
    "        for PROTEOME in os.listdir(protein_path):\n",
    "            if ID in PROTEOME :\n",
    "                FASTA = os.path.join(protein_path, PROTEOME)\n",
    "                OSKAR_SEQ.append(retrieveSeq(SEQ, dataType, FASTA))\n",
    "    SeqIO.write(OSKAR_SEQ, result_file, 'fasta')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (326 of 326) |######################| Elapsed Time: 0:08:21 Time:  0:08:21\n"
     ]
    }
   ],
   "source": [
    "protein_path = '/media/savvy/DATA2/savvy/EXTAVOUR/SOURCES/TSA/TSA_PROTEIN'\n",
    "result_file = '../Data/01_Oskar_identification/oskar_tracker_results/TSA/tsa_oskar_candidates.fasta'\n",
    "save_oskar(TSA, protein_path, 'TSA', result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (98 of 98) |########################| Elapsed Time: 0:00:08 Time:  0:00:08\n"
     ]
    }
   ],
   "source": [
    "protein_path = '/media/lblondel/5D1FA0DA2BE76E76/savy/SOURCES/GCF_PROTEIN'\n",
    "result_file = '../Data/01_Oskar_identification/oskar_tracker_results/GCF/gcf_oskar_candidates.fasta'\n",
    "save_oskar(GCF, protein_path, 'GCF', result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (98 of 98) |########################| Elapsed Time: 0:00:08 Time:  0:00:08\n"
     ]
    }
   ],
   "source": [
    "protein_path = '/media/lblondel/5D1FA0DA2BE76E76/savy/SOURCES/GCA_PROTEIN'\n",
    "result_file = '../Data/01_Oskar_identification/oskar_tracker_results/GCA/gca_oskar_candidates.fasta'\n",
    "save_oskar(GCA, protein_path, 'GCA', result_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Validate candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsa_candidates = '../Data/01_Oskar_identification/oskar_tracker_results/TSA/tsa_oskar_candidates.fasta'\n",
    "oskar_model = '../Data/Oskar_hmm/OSKAR_CONSENSUS.hmm'\n",
    "oskar_validation_results = '../Data/01_Oskar_identification/oskar_tracker_results/TSA/final_tsa_oskar_search.txt'\n",
    "os.system('hmmsearch --cpu 8 --tblout {} {} {}'.format(oskar_validation_results, oskar_model, tsa_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcf_candidates = '../Data/01_Oskar_identification/oskar_tracker_results/GCF/gcf_oskar_candidates.fasta'\n",
    "oskar_model = '../Data/Oskar_hmm/OSKAR_CONSENSUS.hmm'\n",
    "oskar_validation_results = '../Data/01_Oskar_identification/oskar_tracker_results/GCF/final_gcf_oskar_search.txt'\n",
    "os.system('hmmsearch --cpu 8 --tblout {} {} {}'.format(oskar_validation_results, oskar_model, gcf_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gca_candidates = '../Data/01_Oskar_identification/oskar_tracker_results/GCA/gca_oskar_candidates.fasta'\n",
    "oskar_model = '../Data/Oskar_hmm/OSKAR_CONSENSUS.hmm'\n",
    "oskar_validation_results = '../Data/01_Oskar_identification/oskar_tracker_results/GCA/final_gca_oskar_search.txt'\n",
    "os.system('hmmsearch --cpu 8 --tblout {} {} {}'.format(oskar_validation_results, oskar_model, gca_candidates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Oskar duplicate and isoform detection and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from Bio import SeqIO\n",
    "from Bio import SearchIO\n",
    "from Bio import Align\n",
    "from Bio import AlignIO\n",
    "from Bio import Seq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSA_results = pd.read_csv('../Data/01_Oskar_identification/oskar_tracker_results/TSA/tsa_oskar_results.csv')\n",
    "TSA_sequences = '../Data/01_Oskar_identification/oskar_tracker_results/TSA/tsa_oskar_candidates.fasta'\n",
    "hmmerTable = '../Data/01_Oskar_identification/oskar_tracker_results/TSA/final_tsa_oskar_search.txt'\n",
    "TSA_hmmer = SearchIO.read(hmmerTable, 'hmmer3-tab')\n",
    "TSA_filtered_outpath = '../Data/01_Oskar_identification/oskar_tracker_results/TSA/tsa_oskar_filtered.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCF_results = pd.read_csv('../Data/01_Oskar_identification/oskar_tracker_results/GCF/gcf_oskar_results.csv')\n",
    "GCF_sequences = '../Data/01_Oskar_identification/oskar_tracker_results/GCF/gcf_oskar_candidates.fasta'\n",
    "GCF_hmmer = SearchIO.read('../Data/01_Oskar_identification/oskar_tracker_results/GCF/final_gcf_oskar_search.txt', 'hmmer3-tab')\n",
    "GCF_filtered_outpath = '../Data/01_Oskar_identification/oskar_tracker_results/GCF/gcf_oskar_filtered.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE THIS !\n",
    "GCA_results = GCF_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCA_results = pd.read_csv('../Data/01_Oskar_identification/oskar_tracker_results/GCA/gca_oskar_results.csv')\n",
    "# GCA_sequences = '../Data/01_Oskar_identification/oskar_tracker_results/GCA/gca_oskar_candidates.fasta'\n",
    "# GCA_hmmer = SearchIO.read('../Data/01_Oskar_identification/oskar_tracker_results/GCA/final_gca_oskar_search.txt', 'hmmer3-tab')\n",
    "# GCA_filtered_outpath = '../Data/01_Oskar_identification/oskar_tracker_results/GCA/gca_oskar_filtered.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_outpath = '../Data/01_Oskar_identification/oskar_tracker_results/oskar_filtered.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the Hamming distance between string1 and string2.\n",
    "# string1 and string2 should be the same length.\n",
    "def hamming_distance(seq1, seq2): \n",
    "    assert(len(seq1) == len(seq2)) \n",
    "    # Start with a distance of zero, and count up\n",
    "    distance = 0.0\n",
    "    # Loop over the indices of the string\n",
    "    L = len(seq1)\n",
    "    for i in range(L):\n",
    "        # Add 1 to the distance if these two characters are not equal\n",
    "        if seq1[i] != seq2[i]:\n",
    "            distance += 1\n",
    "    # Return the final count of differences\n",
    "    return 1 - distance/L\n",
    "#     return distance\n",
    "\n",
    "def group_sequences(sources):\n",
    "    # Sources definition: [('ID', DataFrame), ('ID', Dataframe)....]\n",
    "    \n",
    "    sequences = {}\n",
    "    for source in sources:\n",
    "        for taxid, oskar_ids in source[1][source[1]['oskar_hits'] != \"None\"][['tax_id', 'oskar_hits']].values:\n",
    "            if taxid not in sequences:\n",
    "                sequences[taxid] = []\n",
    "            sequences[taxid] += [(source[0], i.strip()) for i in oskar_ids.split(',')]\n",
    "    return sequences\n",
    "\n",
    "def make_tmp_seq_groups(sequences, sources):\n",
    "    # sources ->   [('ID', fasta_path), ('ID', fasta_path)....]\n",
    "    name2seq = {}\n",
    "\n",
    "    for source in sources:\n",
    "        fasta = [s for s in SeqIO.parse(source[1], 'fasta')]\n",
    "        for seq in fasta:\n",
    "            if seq.name in name2seq:\n",
    "                print(\"ERROR SEQUENCE ALREADY EXISTS !\")\n",
    "                return False\n",
    "            name2seq[seq.name] = seq\n",
    "\n",
    "    tmp = './tmp/oskars'\n",
    "    if not os.path.isdir('tmp'):\n",
    "        os.mkdir('tmp')\n",
    "    if not os.path.isdir(tmp):\n",
    "        os.mkdir(tmp)\n",
    "    sequences_groups = []\n",
    "    for taxid in sequences:\n",
    "        if len(sequences[taxid]) > 1:\n",
    "            tmpseqs = []\n",
    "            for origin, seq in sequences[taxid]:\n",
    "                s = name2seq[seq]\n",
    "                s.description += '|' + origin\n",
    "                tmpseqs.append(s)\n",
    "            outpath = os.path.join(tmp, '{}.fasta'.format(taxid))\n",
    "            sequences_groups.append(outpath)\n",
    "            f = open(outpath, 'w')\n",
    "            SeqIO.write(tmpseqs, f, 'fasta')\n",
    "    return sequences_groups\n",
    "            \n",
    "def muscle_align(inpath):\n",
    "    \"Command line wrapper for muscle, muscle needs to be in your path !\"\n",
    "    outpath = inpath.replace('fasta', 'aligned.fasta')\n",
    "    cmd = 'muscle -in {} -out {}'.format(inpath, outpath)\n",
    "    os.system(cmd)\n",
    "    return outpath\n",
    "    \n",
    "def align_sequences(sequences_groups):\n",
    "    outpaths = []\n",
    "    for path in tqdm(sequences_groups):\n",
    "        outpath = muscle_align(path)\n",
    "        outpaths.append(outpath)\n",
    "    return outpaths\n",
    "\n",
    "def trim_alignement(alignement):\n",
    "    res = []\n",
    "    for i in range(alignement.get_alignment_length()):\n",
    "        col = alignement[:, i]\n",
    "        if '-' not in col:\n",
    "            res.append([s for s in col])\n",
    "    res = np.array(res).T\n",
    "    for i in range(len(alignement)):\n",
    "        seq = ''.join(list(res[i]))\n",
    "        alignement[i].seq = seq\n",
    "    return alignement\n",
    "    \n",
    "def make_network(alignement_path):\n",
    "    alignement = AlignIO.read(alignement_path, \"fasta\")\n",
    "    trimed = trim_alignement(alignement)\n",
    "    hammings = np.zeros((len(trimed), len(trimed)))\n",
    "    nodes = []\n",
    "    for i in range(len(trimed)):\n",
    "        nodes.append(trimed[i].name)\n",
    "        for j in range(i+1, len(trimed)):\n",
    "            seq1 = trimed[i].seq\n",
    "            seq2 = trimed[j].seq\n",
    "            hammings[i][j] = hamming_distance(seq1, seq2)\n",
    "    M = np.maximum( hammings, hammings.transpose() )\n",
    "    G = nx.from_numpy_matrix(hammings)\n",
    "    for i in G.nodes():\n",
    "        G.node[i]['seq_id'] = nodes[i]\n",
    "    return G, nodes\n",
    "   \n",
    "def find_clusters(alignements_path, threshold=0.9):\n",
    "    clusters = {}\n",
    "    for alignement_path in alignements_path:\n",
    "        taxid = int(alignement_path.split('/')[-1].split('.')[0])\n",
    "        clusters[taxid] = []\n",
    "        G, nodes = make_network(alignement_path)\n",
    "        toremove = []\n",
    "        for n1,n2 in G.edges():\n",
    "            if G.edges[n1, n2]['weight'] < threshold:\n",
    "                toremove.append((n1, n2))\n",
    "        for n1, n2 in toremove:\n",
    "            G.remove_edge(n1, n2)\n",
    "        for cc in nx.connected_components(G):\n",
    "            tmp = []\n",
    "            for i in cc:\n",
    "                tmp.append(nodes[i])\n",
    "            clusters[taxid].append(tmp)\n",
    "    return clusters\n",
    "\n",
    "# def filter_sequences(clusters, TSA_sequences_path, TSA_hmmer_table, GCF_sequences_path, GCF_hmmer_table, uniq_sequences):\n",
    "def filter_sequences(clusters, sources, uniq_sequences):\n",
    "    # [('TSA', TSA_seq_path, TSA_hmmer_path), ('GCF', GCF_seq .......\n",
    "    result = []\n",
    "    sequences = {}\n",
    "    scores = {}\n",
    "\n",
    "    # source element is \n",
    "    # ('ID', sequence_path, hmmer_hit_object)\n",
    "    for source in sources:\n",
    "        handle = SeqIO.parse(source[1], 'fasta')\n",
    "        for s in handle:\n",
    "            sequences[s.name] = (source[0], s)\n",
    "        for hit in source[2]:\n",
    "            scores[hit.id] = hit.evalue\n",
    "    \n",
    "    for s in uniq_sequences:\n",
    "        result.append(sequences[s[1]])\n",
    "            \n",
    "    for taxid in clusters:\n",
    "        for cluster in clusters[taxid]:\n",
    "            tmp_score = []\n",
    "            for seq_id in cluster:\n",
    "                tmp_score.append([scores[seq_id], sequences[seq_id]])\n",
    "            best_seq = sorted(tmp_score, key=lambda x: x[0])\n",
    "            result.append(best_seq[0][1])\n",
    "    return result\n",
    "\n",
    "def clean_sequences(sequences):\n",
    "    cleaned = []\n",
    "    for seq in sequences:\n",
    "        tmp = \"\"\n",
    "        pos = 0\n",
    "        for l in seq.seq:\n",
    "            if l != 'X':\n",
    "                tmp += l\n",
    "            elif pos < 550:\n",
    "                tmp += l\n",
    "            else:\n",
    "                break\n",
    "            pos += 1\n",
    "        seq.seq = Seq.Seq(tmp)\n",
    "        cleaned.append(seq)\n",
    "    return cleaned\n",
    "\n",
    "def decorate_sequences(sequences, TSA_metadatas, GCF_metadatas, GCA_metadatas=None):\n",
    "    results = []\n",
    "    for s in sequences:\n",
    "        tag = s[0]\n",
    "        seq = s[1] \n",
    "        if tag == 'TSA':\n",
    "            TSA_ID = seq.name[0:6]\n",
    "            metadata = TSA_metadatas[TSA_metadatas['tsa_abrv'] == TSA_ID][['species', 'family_name', 'order_name']].values[0]\n",
    "        if tag == 'GCF':\n",
    "            if len(seq.description.split('|')) != 4:\n",
    "                GCF_specie = seq.description.split('[')[-1].split(']')[0]\n",
    "                metadata = GCF_metadatas[GCF_metadatas['species'] == GCF_specie][['species', 'family_name', 'order_name']].values[0]\n",
    "            else:\n",
    "                metadata = seq.description.split('|')\n",
    "        if tag == 'GCA':\n",
    "            if len(seq.description.split('|')) != 4:\n",
    "                GCA_specie = seq.description.split('[')[-1].split(']')[0]\n",
    "                metadata = GCA_metadatas[GCA_metadatas['species'] == GCA_specie][['species', 'family_name', 'order_name']].values[0]\n",
    "            else:\n",
    "                metadata = seq.description.split('|')\n",
    "        seq.description = \"{}|{}|{}|{}\".format(metadata[0], metadata[1], metadata[2], tag)\n",
    "        results.append(seq)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first group the sequences by unique taxa\n",
    "sequences = group_sequences([\n",
    "    ('TSA', TSA_results),\n",
    "    ('GCF', GCF_results),\n",
    "#     ('GCA', GCA_results),\n",
    "])\n",
    "\n",
    "uniq_sequences = [sequences[k][0] for k in sequences if len(sequences[k]) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we create fasta files for each taxa, only if this taxa has more than one sequence\n",
    "sequences_groups = make_tmp_seq_groups(\n",
    "    sequences,\n",
    "    [('TSA', TSA_sequences),\n",
    "     ('GCF', GCF_sequences),\n",
    "#      ('GCA', GCA_sequences)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127b225b88054b839b64b49197873a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=78), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# We use Muscle to align those sequences (from the fasta files we just created)\n",
    "alignements_path = align_sequences(sequences_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use graph theory (simple edge removal by threshold) to find sequences cluster within the sequence group\n",
    "clusters = find_clusters(alignements_path, threshold=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We filter the sequences keeping the best E-value sequence for each cluster group,\n",
    "# and add back the sequences that were unique already\n",
    "filtered_sequences = filter_sequences(clusters, [\n",
    "                                                ('TSA', TSA_sequences, TSA_hmmer),\n",
    "                                                ('GCF', GCF_sequences, GCF_hmmer),\n",
    "#                                                 ('GCA', GCA_sequences, GCA_hmmer)\n",
    "                                                ], \n",
    "                                      uniq_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We decorate the sequences for further processing with species, family and order name as well as a datatype tag \"TSA\"\n",
    "decorated_sequences = decorate_sequences(filtered_sequences, TSA_results, GCF_results ,GCA_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sequences = clean_sequences(decorated_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save our sequence group\n",
    "f = open(filtered_outpath, 'w')\n",
    "SeqIO.write(cleaned_sequences, f, 'fasta')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sequences\n",
      "TSA: 326\n",
      "GCF: 98\n",
      "Total: 424\n",
      "The algorithm filtered out 122 sequences\n",
      "Final sequence count is 302. TSA:227 | GCF:75\n"
     ]
    }
   ],
   "source": [
    "handle = SeqIO.parse(TSA_sequences, 'fasta')\n",
    "total_seq = 0\n",
    "for s in handle:\n",
    "    total_seq += 1\n",
    "\n",
    "tsa_rem = total_seq\n",
    "handle = SeqIO.parse(GCF_sequences, 'fasta')\n",
    "for s in handle:\n",
    "    total_seq += 1\n",
    "print(\"Starting sequences\")\n",
    "print(\"TSA:\", tsa_rem)\n",
    "print(\"GCF:\", total_seq-tsa_rem)\n",
    "print(\"Total:\", total_seq)\n",
    "\n",
    "\n",
    "    \n",
    "handle = SeqIO.parse(filtered_outpath, 'fasta')\n",
    "filtered_seq = 0\n",
    "tsa_keep = 0\n",
    "gcf_keep = 0\n",
    "for s in handle:\n",
    "    filtered_seq += 1\n",
    "    tag = s.description.split('|')[-1]\n",
    "    if tag == 'TSA':\n",
    "        tsa_keep += 1\n",
    "    elif tag == 'GCF':\n",
    "        gcf_keep += 1\n",
    "\n",
    "print(\"The algorithm filtered out {} sequences\".format(total_seq-filtered_seq))\n",
    "print(\"Final sequence count is {}. TSA:{} | GCF:{}\".format(filtered_seq, tsa_keep, gcf_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3412535d7da741c390200a909535fc5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=58), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequences saved !\n"
     ]
    }
   ],
   "source": [
    "# Redoing the same process but with only one source type at a time for count purposes\n",
    "\n",
    "# Doing TSA\n",
    "sequences = group_sequences([\n",
    "    ('TSA', TSA_results),\n",
    "])\n",
    "uniq_sequences = [sequences[k][0] for k in sequences if len(sequences[k]) == 1]\n",
    "sequences_groups = make_tmp_seq_groups(\n",
    "    sequences,\n",
    "    [('TSA', TSA_sequences),\n",
    "    ])\n",
    "alignements_path = align_sequences(sequences_groups)\n",
    "clusters = find_clusters(alignements_path, threshold=0.80)\n",
    "filtered_sequences = filter_sequences(clusters, [\n",
    "                                                ('TSA', TSA_sequences, TSA_hmmer),\n",
    "                                                ], \n",
    "                                      uniq_sequences)\n",
    "decorated_sequences = decorate_sequences(filtered_sequences, TSA_results, GCF_results, GCA_results)\n",
    "cleaned_sequences = clean_sequences(decorated_sequences)\n",
    "\n",
    "# We save our sequence group\n",
    "f = open(TSA_filtered_outpath, 'w')\n",
    "SeqIO.write(cleaned_sequences, f, 'fasta')\n",
    "f.close()\n",
    "print(\"Sequences saved !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sequences\n",
      "TSA: 326\n",
      "GCF: 98\n",
      "Total: 424\n",
      "The algorithm filtered out 122 sequences\n",
      "Final sequence count is 302. TSA:227 | GCF:75\n"
     ]
    }
   ],
   "source": [
    "handle = SeqIO.parse(TSA_sequences, 'fasta')\n",
    "total_seq = 0\n",
    "for s in handle:\n",
    "    total_seq += 1\n",
    "\n",
    "tsa_rem = total_seq\n",
    "handle = SeqIO.parse(GCF_sequences, 'fasta')\n",
    "for s in handle:\n",
    "    total_seq += 1\n",
    "print(\"Starting sequences\")\n",
    "print(\"TSA:\", tsa_rem)\n",
    "print(\"GCF:\", total_seq-tsa_rem)\n",
    "print(\"Total:\", total_seq)\n",
    "\n",
    "\n",
    "    \n",
    "handle = SeqIO.parse(filtered_outpath, 'fasta')\n",
    "filtered_seq = 0\n",
    "tsa_keep = 0\n",
    "gcf_keep = 0\n",
    "for s in handle:\n",
    "    filtered_seq += 1\n",
    "    tag = s.description.split('|')[-1]\n",
    "    if tag == 'TSA':\n",
    "        tsa_keep += 1\n",
    "    elif tag == 'GCF':\n",
    "        gcf_keep += 1\n",
    "\n",
    "print(\"The algorithm filtered out {} sequences\".format(total_seq-filtered_seq))\n",
    "print(\"Final sequence count is {}. TSA:{} | GCF:{}\".format(filtered_seq, tsa_keep, gcf_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc2a783f7ab44e18f24c70ffd9b12be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequences saved !\n"
     ]
    }
   ],
   "source": [
    "# Doing GCF\n",
    "sequences = group_sequences([\n",
    "    ('GCF', GCF_results),\n",
    "])\n",
    "uniq_sequences = [sequences[k][0] for k in sequences if len(sequences[k]) == 1]\n",
    "sequences_groups = make_tmp_seq_groups(\n",
    "    sequences,\n",
    "    [\n",
    "     ('GCF', GCF_sequences),\n",
    "    ])\n",
    "alignements_path = align_sequences(sequences_groups)\n",
    "clusters = find_clusters(alignements_path, threshold=0.80)\n",
    "filtered_sequences = filter_sequences(clusters, [\n",
    "                                                ('GCF', GCF_sequences, GCF_hmmer),\n",
    "                                                ], \n",
    "                                      uniq_sequences)\n",
    "decorated_sequences = decorate_sequences(filtered_sequences, TSA_results, GCF_results ,GCA_results)\n",
    "cleaned_sequences = clean_sequences(decorated_sequences)\n",
    "\n",
    "# We save our sequence group\n",
    "f = open(GCF_filtered_outpath, 'w')\n",
    "SeqIO.write(cleaned_sequences, f, 'fasta')\n",
    "f.close()\n",
    "print(\"Sequences saved !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing GCA\n",
    "sequences = group_sequences([\n",
    "    ('GCA', GCA_results),\n",
    "])\n",
    "uniq_sequences = [sequences[k][0] for k in sequences if len(sequences[k]) == 1]\n",
    "sequences_groups = make_tmp_seq_groups(\n",
    "    sequences,\n",
    "    [\n",
    "     ('GCA', GCA_sequences)\n",
    "    ])\n",
    "alignements_path = align_sequences(sequences_groups)\n",
    "clusters = find_clusters(alignements_path, threshold=0.80)\n",
    "filtered_sequences = filter_sequences(clusters, [\n",
    "                                                ('GCA', GCA_sequences, GCA_hmmer)\n",
    "                                                ], \n",
    "                                      uniq_sequences)\n",
    "decorated_sequences = decorate_sequences(filtered_sequences, TSA_results, GCF_results ,GCA_results)\n",
    "cleaned_sequences = clean_sequences(decorated_sequences)\n",
    "\n",
    "# We save our sequence group\n",
    "f = open(GCA_filtered_outpath, 'w')\n",
    "SeqIO.write(cleaned_sequences, f, 'fasta')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genome_id</th>\n",
       "      <th>tax_id</th>\n",
       "      <th>species</th>\n",
       "      <th>family_id</th>\n",
       "      <th>family_name</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_name</th>\n",
       "      <th>bioproject</th>\n",
       "      <th>biosample</th>\n",
       "      <th>download_status</th>\n",
       "      <th>lotus_hits</th>\n",
       "      <th>osk_hits</th>\n",
       "      <th>oskar_hits</th>\n",
       "      <th>pgc_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GCF_003285875.2</td>\n",
       "      <td>47314</td>\n",
       "      <td>Drosophila novamexicana</td>\n",
       "      <td>7214.0</td>\n",
       "      <td>Drosophilidae</td>\n",
       "      <td>7147</td>\n",
       "      <td>Diptera</td>\n",
       "      <td>PRJNA475270</td>\n",
       "      <td>SAMN09383009</td>\n",
       "      <td>True</td>\n",
       "      <td>XP_030572142.1,XP_030558430.1,XP_030573785.1,X...</td>\n",
       "      <td>XP_030572142.1,XP_030573402.1</td>\n",
       "      <td>XP_030572142.1</td>\n",
       "      <td>Inheritance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>GCF_006496715.1</td>\n",
       "      <td>7160</td>\n",
       "      <td>Aedes albopictus</td>\n",
       "      <td>7157.0</td>\n",
       "      <td>Culicidae</td>\n",
       "      <td>7147</td>\n",
       "      <td>Diptera</td>\n",
       "      <td>PRJNA530512</td>\n",
       "      <td>SAMN11317331</td>\n",
       "      <td>True</td>\n",
       "      <td>XP_019540707.2,XP_019558301.2,XP_029723149.1,X...</td>\n",
       "      <td>XP_019558301.2,XP_019540707.2,XP_029710371.1,X...</td>\n",
       "      <td>XP_019558301.2,XP_019540707.2</td>\n",
       "      <td>Inheritance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>GCF_003285725.1</td>\n",
       "      <td>7225</td>\n",
       "      <td>Scaptodrosophila lebanonensis</td>\n",
       "      <td>7214.0</td>\n",
       "      <td>Drosophilidae</td>\n",
       "      <td>7147</td>\n",
       "      <td>Diptera</td>\n",
       "      <td>PRJNA475270</td>\n",
       "      <td>SAMN09383169</td>\n",
       "      <td>True</td>\n",
       "      <td>XP_030374856.1,XP_030388337.1,XP_030388338.1,X...</td>\n",
       "      <td>XP_030374856.1</td>\n",
       "      <td>XP_030374856.1</td>\n",
       "      <td>Inheritance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>GCF_003285905.1</td>\n",
       "      <td>7224</td>\n",
       "      <td>Drosophila hydei</td>\n",
       "      <td>7214.0</td>\n",
       "      <td>Drosophilidae</td>\n",
       "      <td>7147</td>\n",
       "      <td>Diptera</td>\n",
       "      <td>PRJNA475270</td>\n",
       "      <td>SAMN09383128</td>\n",
       "      <td>True</td>\n",
       "      <td>XP_023173869.2,XP_023162524.2,XP_023167456.1,X...</td>\n",
       "      <td>XP_023173869.2</td>\n",
       "      <td>XP_023173869.2</td>\n",
       "      <td>Inheritance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>GCF_005508785.1</td>\n",
       "      <td>7029</td>\n",
       "      <td>Acyrthosiphon pisum</td>\n",
       "      <td>27482.0</td>\n",
       "      <td>Aphididae</td>\n",
       "      <td>7524</td>\n",
       "      <td>Hemiptera</td>\n",
       "      <td>PRJNA496478</td>\n",
       "      <td>SAMN10253041</td>\n",
       "      <td>True</td>\n",
       "      <td>XP_008185199.1,XP_016663178.1,XP_029346403.1,X...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Induction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>GCF_000475195.1</td>\n",
       "      <td>121845</td>\n",
       "      <td>Diaphorina citri</td>\n",
       "      <td>1585420.0</td>\n",
       "      <td>Liviidae</td>\n",
       "      <td>7524</td>\n",
       "      <td>Hemiptera</td>\n",
       "      <td>PRJNA29447</td>\n",
       "      <td>SAMN00100712</td>\n",
       "      <td>True</td>\n",
       "      <td>XP_026676435.1,XP_026676086.1,XP_008488072.1,X...</td>\n",
       "      <td>XP_008484229.1,XP_026687642.1,XP_026681044.1</td>\n",
       "      <td>None</td>\n",
       "      <td>Induction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>GCF_000472105.1</td>\n",
       "      <td>28584</td>\n",
       "      <td>Drosophila suzukii</td>\n",
       "      <td>7214.0</td>\n",
       "      <td>Drosophilidae</td>\n",
       "      <td>7147</td>\n",
       "      <td>Diptera</td>\n",
       "      <td>PRJNA213258</td>\n",
       "      <td>SAMN02953868</td>\n",
       "      <td>True</td>\n",
       "      <td>XP_016941563.1,XP_016928705.1,XP_016928704.1,X...</td>\n",
       "      <td>XP_016941563.1,XP_016941489.1</td>\n",
       "      <td>XP_016941563.1</td>\n",
       "      <td>Inheritance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>GCF_000469605.1</td>\n",
       "      <td>7462</td>\n",
       "      <td>Apis dorsata</td>\n",
       "      <td>7458.0</td>\n",
       "      <td>Apidae</td>\n",
       "      <td>7399</td>\n",
       "      <td>Hymenoptera</td>\n",
       "      <td>PRJNA174631</td>\n",
       "      <td>SAMN02954476</td>\n",
       "      <td>True</td>\n",
       "      <td>XP_006612511.1,XP_006614786.1,XP_006609155.1,X...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Inheritance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>GCF_000005925.1</td>\n",
       "      <td>7260</td>\n",
       "      <td>Drosophila willistoni</td>\n",
       "      <td>7214.0</td>\n",
       "      <td>Drosophilidae</td>\n",
       "      <td>7147</td>\n",
       "      <td>Diptera</td>\n",
       "      <td>PRJNA12664</td>\n",
       "      <td>SAMN02953653</td>\n",
       "      <td>True</td>\n",
       "      <td>XP_023034501.1,XP_002070281.2,XP_023033702.1,X...</td>\n",
       "      <td>XP_002070281.2,XP_002065327.1</td>\n",
       "      <td>XP_002070281.2</td>\n",
       "      <td>Inheritance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>GCF_000005245.1</td>\n",
       "      <td>7244</td>\n",
       "      <td>Drosophila virilis</td>\n",
       "      <td>7214.0</td>\n",
       "      <td>Drosophilidae</td>\n",
       "      <td>7147</td>\n",
       "      <td>Diptera</td>\n",
       "      <td>PRJNA12688</td>\n",
       "      <td>SAMN02953641</td>\n",
       "      <td>True</td>\n",
       "      <td>XP_002053269.1,XP_002050881.2,XP_015029355.1,X...</td>\n",
       "      <td>XP_002053269.1,XP_002054219.1</td>\n",
       "      <td>XP_002053269.1</td>\n",
       "      <td>Inheritance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           genome_id  tax_id                        species  family_id  \\\n",
       "0    GCF_003285875.2   47314        Drosophila novamexicana     7214.0   \n",
       "1    GCF_006496715.1    7160               Aedes albopictus     7157.0   \n",
       "2    GCF_003285725.1    7225  Scaptodrosophila lebanonensis     7214.0   \n",
       "3    GCF_003285905.1    7224               Drosophila hydei     7214.0   \n",
       "4    GCF_005508785.1    7029            Acyrthosiphon pisum    27482.0   \n",
       "..               ...     ...                            ...        ...   \n",
       "127  GCF_000475195.1  121845               Diaphorina citri  1585420.0   \n",
       "128  GCF_000472105.1   28584             Drosophila suzukii     7214.0   \n",
       "129  GCF_000469605.1    7462                   Apis dorsata     7458.0   \n",
       "130  GCF_000005925.1    7260          Drosophila willistoni     7214.0   \n",
       "131  GCF_000005245.1    7244             Drosophila virilis     7214.0   \n",
       "\n",
       "       family_name  order_id   order_name   bioproject     biosample  \\\n",
       "0    Drosophilidae      7147      Diptera  PRJNA475270  SAMN09383009   \n",
       "1        Culicidae      7147      Diptera  PRJNA530512  SAMN11317331   \n",
       "2    Drosophilidae      7147      Diptera  PRJNA475270  SAMN09383169   \n",
       "3    Drosophilidae      7147      Diptera  PRJNA475270  SAMN09383128   \n",
       "4        Aphididae      7524    Hemiptera  PRJNA496478  SAMN10253041   \n",
       "..             ...       ...          ...          ...           ...   \n",
       "127       Liviidae      7524    Hemiptera   PRJNA29447  SAMN00100712   \n",
       "128  Drosophilidae      7147      Diptera  PRJNA213258  SAMN02953868   \n",
       "129         Apidae      7399  Hymenoptera  PRJNA174631  SAMN02954476   \n",
       "130  Drosophilidae      7147      Diptera   PRJNA12664  SAMN02953653   \n",
       "131  Drosophilidae      7147      Diptera   PRJNA12688  SAMN02953641   \n",
       "\n",
       "     download_status                                         lotus_hits  \\\n",
       "0               True  XP_030572142.1,XP_030558430.1,XP_030573785.1,X...   \n",
       "1               True  XP_019540707.2,XP_019558301.2,XP_029723149.1,X...   \n",
       "2               True  XP_030374856.1,XP_030388337.1,XP_030388338.1,X...   \n",
       "3               True  XP_023173869.2,XP_023162524.2,XP_023167456.1,X...   \n",
       "4               True  XP_008185199.1,XP_016663178.1,XP_029346403.1,X...   \n",
       "..               ...                                                ...   \n",
       "127             True  XP_026676435.1,XP_026676086.1,XP_008488072.1,X...   \n",
       "128             True  XP_016941563.1,XP_016928705.1,XP_016928704.1,X...   \n",
       "129             True  XP_006612511.1,XP_006614786.1,XP_006609155.1,X...   \n",
       "130             True  XP_023034501.1,XP_002070281.2,XP_023033702.1,X...   \n",
       "131             True  XP_002053269.1,XP_002050881.2,XP_015029355.1,X...   \n",
       "\n",
       "                                              osk_hits  \\\n",
       "0                        XP_030572142.1,XP_030573402.1   \n",
       "1    XP_019558301.2,XP_019540707.2,XP_029710371.1,X...   \n",
       "2                                       XP_030374856.1   \n",
       "3                                       XP_023173869.2   \n",
       "4                                                 None   \n",
       "..                                                 ...   \n",
       "127       XP_008484229.1,XP_026687642.1,XP_026681044.1   \n",
       "128                      XP_016941563.1,XP_016941489.1   \n",
       "129                                               None   \n",
       "130                      XP_002070281.2,XP_002065327.1   \n",
       "131                      XP_002053269.1,XP_002054219.1   \n",
       "\n",
       "                        oskar_hits     pgc_mode  \n",
       "0                   XP_030572142.1  Inheritance  \n",
       "1    XP_019558301.2,XP_019540707.2  Inheritance  \n",
       "2                   XP_030374856.1  Inheritance  \n",
       "3                   XP_023173869.2  Inheritance  \n",
       "4                             None    Induction  \n",
       "..                             ...          ...  \n",
       "127                           None    Induction  \n",
       "128                 XP_016941563.1  Inheritance  \n",
       "129                           None  Inheritance  \n",
       "130                 XP_002070281.2  Inheritance  \n",
       "131                 XP_002053269.1  Inheritance  \n",
       "\n",
       "[132 rows x 14 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCF_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align the final result with hmmalign and refine with muscle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hmmalign ../Data/Oskar_hmm/OSKAR_CONSENSUS.hmm ../Data/01_Oskar_identification/oskar_tracker_results/oskar_filtered.fasta > ../Data/01_Oskar_identification/oskar_tracker_results/oskar_filtered.hmmaligned.sto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "i = open('../Data/01_Oskar_identification/oskar_tracker_results/oskar_filtered.hmmaligned.sto')\n",
    "o = open('../Data/01_Oskar_identification/oskar_tracker_results/oskar_filtered.hmmaligned.fasta', 'w')\n",
    "\n",
    "SeqIO.convert(i, 'stockholm', o, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MUSCLE v3.8.31 by Robert C. Edgar\n",
      "\n",
      "http://www.drive5.com/muscle\n",
      "This software is donated to the public domain.\n",
      "Please cite: Edgar, R.C. Nucleic Acids Res 32(5), 1792-97.\n",
      "\n",
      "00:00:46    41 MB(-3%)  Iter   1  100.00%  Refine biparts\n",
      "00:01:25    42 MB(-3%)  Iter   2  100.00%  Refine biparts\n",
      "00:02:02    44 MB(-3%)  Iter   3  100.00%  Refine biparts\n",
      "00:02:12    44 MB(-3%)  Iter   4  100.00%  Refine biparts\n",
      "00:02:12    44 MB(-3%)  Iter   4  100.00%  Refine biparts\n"
     ]
    }
   ],
   "source": [
    "!muscle -in ../Data/01_Oskar_identification/oskar_tracker_results/oskar_filtered.hmmaligned.fasta -out ../Data/01_Oskar_identification/oskar_tracker_results/oskar_filtered.aligned.fasta -refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
